### YOLOv10：实时端到端目标检测



![image](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1243709065485766656/1243709065485766656_cut_Figure_1.png)







### 摘要

在过去的几年里，YOLOs 已成为实时目标检测领域的主要范例，因为它们在计算成本和检测性能之间取得了有效的平衡。研究人员已经探索了YOLOs 的体系结构设计、优化目标、数据增强策略等，并取得了显著进展。然而，后处理过程中对非极大抑制（NMS）的依赖阻碍了YOLOs 的端到端部署，并对推断延迟产生了不利影响。此外，YOLOs 各个组件的设计缺乏全面彻底的检查，导致明显的计算冗余并限制了模型的能力。这使得效率较低，同时还有很大的性能提升潜力。在这项工作中，我们旨在从后处理和模型架构两个方面进一步提高YOLOs 的性能效率边界。为此，我们首先提出了YOLOs NMS 免训练的一致双重分配方法，它带来了竞争性的性能和低推断延迟。此外，我们引入了面向整体效率准确率驱动的YOLOs 模型设计策略。我们在效率和准确率的角度综合优化了YOLOs 的各个组件，极大地减少了计算开销并增强了能力。我们的努力的结果是一代新的实时端到端对象检测YOLO 系列，称为YOLOv10。广泛的实验表明，YOLOv10 在各种模型规模上都实现了最先进的性能和效率。例如，在与COCO 相同的AP 情况下，我们的YOLOv10-S 比RT-DETR-R18 快1.8 倍，同时还具有更小的参数数量和浮点运算次数。与YOLOv9-C 相比，YOLOv10-B 在相同性能的情况下具有更低的延迟和更少的参数（降低了25%）。代码：https://github.com/THU-MIG/yolov10



### 1. 简介



实时物体检测一直是 计算机视觉领域研究的重点，旨在以低延迟准确预测图像中 物体的类别和位置。它被广泛应用于各种实际应用中，包括自动驾驶[3]、机器人导航[11]和目标跟踪[66]等。近年来，研究人员专注于设计基于卷积神经网络（CNN）的对象检测器以实现实时检测[18,22,43,44,45,51,12]。其中，YOLO由于在性能和效率之间取得了巧妙的平衡而越来越受欢迎[2,19,27,19,20,59,54,64,7,65,16,27]。YOLO的检测管道由两部分组成：模型前向过程和NMS后处理。然而，两者仍然存在缺陷，导致次优的精度-延迟边界。



具体来说，YOLOv5在训练过程中通常采用一对一标签分配策略，其中一个真实对象对应多个正样本。尽管性能优异，但这种方法需要在推断过程中使用NMS来选择最佳正预测结果，从而降低推断速度，并使性能敏感于NMS的超参数，这阻碍了YOLOv5实现最优端到端部署[71]。解决此问题的一行代码是采用最近引入的端到端DETR架构[4, 74, 67, 28, 34, 40, 61]。例如，RT-DETR[71]提出了一种高效的混合编码器和最小不确定度查询选择方法，推动DETR进入实时应用领域。然而，部署DETR固有的复杂性阻碍了其在准确性和速度之间达到最佳平衡的能力。另一条路线是探索基于卷积神经网络(CNN)的检测器的端到端检测，它们通常利用一对一分配策略抑制冗余预测[5, 49, 60, 73, 16]。但是，他们通常会引入额外的推理开销或实现次优性能。



此外，YOLO 的模型架构设计仍然是一个基本挑战，这对准确性和速度有着重要的影响。为了实现更高效、有效的模型架构，研究人员探索了不同的设计策略。各种主要计算单元被用于提高主干网络的特征提取能力，包括Darknet [43,44,45]、CSPNet [2]、EfficientRep [27] 和ELAN [56, 58] 等。对于颈部，PAN [35]、BiC [27]、GD [54] 和RepGFPN [65] 等方法被用来增强多尺度特征融合。此外，还研究了模型缩放策略[56, 55] 和重参数化技术[10, 27]。虽然这些努力取得了显著进展，但从效率和准确性角度对YOLO的各种组件进行全面检查仍然缺乏。因此，在YOLO中仍存在相当大的计算冗余，导致参数利用效率低下和次优效率。此外，由此产生的约束模型能力也导致性能下降，留下了充足的改进空间。



在本文中，我们旨在解决这些问题，并进一步提高YOLO模型的速度准确率边界。我们在检测管道的后处理和模型架构中都针对这两个方面进行了优化。为此，我们首先通过引入双标签分配和一致匹配度量的方法来解决后处理中的冗余预测问题，从而实现免NMS的YOLO模型的一致双重赋值策略。这使得模型在训练过程中能够享受丰富而和谐的监督，同时在推断过程中消除对NMS的需求，以达到高效且具有竞争力的表现。其次，我们提出了全面考虑效率和准确性的模型设计策略，用于模型架构的设计。为了提高效率，我们提出轻量级分类头、空间通道分离下采样和排名引导块设计等方法，以减少计算冗余并实现更高效的架构。为了提高准确性，我们探索了大核卷积，并提出了有效的部分自注意力模块来增强模型能力，利用低成本下的性能提升潜力。



根据这些方法，我们成功地实现了一个新的实时端到端检测器家族，具有不同的模型规模，即YOLOv10-N/S/M/B/L/X。在标准对象检测基准COCO上进行的大量实验[33] 表明，与之前的最先进的模型相比，我们的YOLOv10可以在各种模型规模下显著提高计算精度权衡。如图1所示，在相似的表现下，我们的YOLOv10-S/X比RT-DETR-R18/R101快1.8倍/1.3倍。与YOLOv9-C相比，YOLOv10-B在相同性能的情况下延迟减少了46%。此外，YOLOv10具有高度有效的参数利用率。我们的YOLOv10-L/X优于YOLOv8-L/X，分别在更少的参数（1.8倍和2.3倍）的情况下提高了0.3 AP和0.5 AP。YOLOv10-M实现了与YOLOv9-M / YOLO-MS相比，AP相似度高，参数减少了23％/ 31％。我们希望我们的工作能够激发该领域的进一步研究和发展。



### 2 相关工作



实时目标检测。实时目标检测旨在在低延迟下对物体进行分类和定位，这对现实世界的应用至关重要。过去几年来，人们已经做了大量工作来开发高效的检测器。特别是YOLO系列脱颖而出成为主流。YOLOv1、YOLOv2和YOLOv3识别了典型的检测架构，包括三个部分：骨干网络、颈部和头部。YOLOv4[[2](https://ieeexplore.ieee.org/document/9165889)]和YOLOv5[[19](https://ieeexplore.ieee.org/document/9165889)]引入了CSPNet设计来代替Darknet，并结合数据增强策略、增强PAN和各种模型规模等。YOLOv6[[27](https://ieeexplore.ieee.org/document/9165889)]分别提出了BiC和SimCSPSPPF以供颈部和背部使用，并采用锚点辅助训练和自我蒸馏策略。YOLOv7[[56](https://ieeexplore.ieee.org/document/9165889)]引入E-ELAN以实现丰富的梯度流路径，并探索了几种可训练的免费物品方法。YOLOv8[[20](https://ieeexplore.ieee.org/document/9165889)]提出了C2f构建块以有效提取和融合特征。Gold-YOLO[[54](https://tongyi.aliyun.com/zhiwen/URL54)]提供了先进的GD机制以提高多尺度特征融合能力。YOLOv9[[59](https://tongyi.aliyun.com/zhiwen/URL59)]提出了GELAN以改进架构并引入PGI以扩展训练过程。



端到端目标检测器。端到端目标检测已经从传统的流水线范式中崛起，提供了简化的架构。[48] DECAPROP [4]引入了自注意力架构，并使用匈牙利损失来实现一一匹配预测，从而消除手工制作的组件和后处理。此后，提出了各种DECART变体以提高其性能和效率。可变形-DECAPROP[74]利用多尺度可变形注意模块加速收敛速度。DINO[67]将对比度去噪、混合查询选择和双次前向方案整合到DECAPROPs中。RT-DECAPROP[71]进一步设计了高效的混合编码器，并提出最小化不确定性查询选择以提高准确性和延迟。另一条实现端到端目标检测的方法是基于CNN检测器。Learnable NMS[23] 和关系网络[25]为检测器提供了一个网络来去除重复的预测。OneNet[49]和DeFCN[60]提出了逐对匹配策略，使全卷积网络能够进行端到端的目标检测。FCOSPSS[73]引入一个正样本选择器来选择最佳样本用于预测。



### 3 方法



### 3.1 NMS-Free训练的双重分配



在训练过程中，YOLOs [20, 59, 27, 64] 通常使用TAL[14]为每个实例分配多个正样本。采用一对一配对的方法产生了大量的监督信号，促进了优化并取得了优越的表现。然而，它需要YOLOs依赖NMS后处理，这导致部署时次优的推理效率。虽然先前的工作[49, 60, 73, 5]探索了一对一匹配来抑制冗余预测，但它们通常会引入额外的推理开销或产生次优性能。在这项工作中，我们提出了一种无需NMS的训练策略，用于具有双重标签分配和一致匹配度量的YOLOs，实现了高效率和竞争力的表现。



双标签分配。与一对一配对不同，一对多配对为每个真实标签分配一个预测标签，避免了后处理中的非极大抑制（NMS）。然而，它会导致弱监督，从而导致较低的准确度和收敛速度[75]。幸运的是，这种缺陷可以通过一对多配对进行补偿[5]。为了实现这一目标，我们在YOLO中引入了双标签分配来结合这两种策略的优点。具体来说，如图 2 (a) 所示，我们为 YOLO 添加了一个额外的一对一头部。它保留了一致的结构，并采用与原始的一对多分支相同的学习目标，但利用一对一匹配获得标签分配。在训练过程中，两个头与模型一起联合优化，允许骨干网络和脖子从一对多分支提供的丰富监督信号中受益。在推理过程中，我们丢弃一对多头，并使用一对一头进行预测。这使得 YOLO 能够端到端部署，而无需付出任何额外的推断成本。此外，在一对一匹配中，我们采用了顶部选择，实现了与匈牙利匹配[4]相同的性能，同时减少了额外的训练时间。



![image](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1243709065485766656/1243709065485766656_cut_Figure_2.png)







一致匹配度量。在分配期间，一对一和一对多方法都使用一个度量来定量评估预测与实例之间的吻合程度。为了实现两个分支的预测感知匹配，我们采用统一的匹配度量，即其中p表示分类分数，预测框中括号和实例框中括号分别表示预测和实例的边界框。s表示空间先验，指示预测锚点是否在实例中 [20, 59, 27, 64]。α和β是两个重要的超参数，平衡语义预测任务和位置回归任务的影响。我们用mo2m=m（αo2m，βo2m）和mo2o=m（αo2o，βo2o）表示多对一和一对一指标。这些指标影响两头标签分配和监督信息。

在 双标签 分配中，一对一分支提供的监督信号比一对多分支丰富得多。直观地说，如果我们能够协调一对一头部与一对多头部之间的监督，那么我们可以优化一对一头部朝着一对多头部的方向进行优化。因此，在推理过程中，一对一头部可以提供更好的样本质量，从而实现更好的性能。为此，我们首先分析了两个头之间的监督差距。由于训练过程中的随机性，我们在开始时对两个具有相同值并产生相同预测的头进行了检查，即一对一头部和一对多头部为每个预测实例生成相同的 p 和 IoU。请注意，两个分支的回归目标并不冲突，因为匹配的预测共享相同的靶向，而未匹配的预测则被忽略。因此，监督鸿沟存在于不同的分类目标之间。给定一个实例，我们用它的最大IoU来表示它与预测的最大重叠度 u*，以及最大的一对多和一对一匹配分数 m**{o_2m} 和 m**{o_2o}。假设一对多分支产生了正样本 Ω，一对一分支选择了第 i 个预测，其指标为 m*o2o,i=m*o2o，那么我们可以推导出分类目标：to2m,j=u*·m2m,jm*≤u*对于 j∈Ω 和 to2o,i=u*·m2o,i o2m m*=u*o2o 作为任务对齐损失[20,59,27,64,14]。因此，通过不同分类目标之间的 1 水平距离[41]，可以得出两个分支之间的监督鸿沟，即我们观察到，随着 to2m,i 的增加，差距会减小，也就是说，在 Ω 中，i 在排名上更高。当 to2m,i = u* 时达到最小值，即在图 2(a) 中，i 是 Ω 中最好的正样本。为了实现这一点，我们提出了一致匹配度量，即 αo2o=r·αo2m 和 βo2o=r·βo2m，这意味着 mo2o=mro2m。因此，一对一头部的最佳正样本也是多对一头部的最佳正样本。因此，两个头可以被一致地和谐地优化。为了简单起见，默认情况下取 r=1，即 αo2o=αo2m 和 βo2o=βo2m。为了验证改进后的监督对齐，我们在训练后计算了多对一结果中前 1/5/10 的一对一匹配对数。如图 2(b) 所示，一致匹配度量下的一致性得到了提高。欲深入了解数学证明，请参阅附录。





### 3.2 整体效率与准确率驱动模型设计



除了后处理之外，YOLO模型体系结构也给效率与准确性之间的权衡带来了巨大挑战。[45][7][27]尽管之前的研究探索了各种设计策略，

![image](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1243709065485766656/1243709065485766656_cut_Figure_3.png)

YOLOs 中各种组件的全面检查仍然不足。因此，该模型架构存在显著的计算冗余和能力受限，这阻碍了其实现高效率和性能的潜力。在这里，我们旨在从效率和准确性的角度对YOLOs进行整体设计。效率驱动的设计模型。YOLO 的组件包括茎、下采样层、基本构建块的阶段和头部。茎部很少有计算成本，因此我们在其他三个部分进行效率驱动型设计。



(1) 轻量级分类头。YOLO 系列中，分类头和回归头通常共享相同的架构。然而，在计算开销方面它们存在显著差异。例如，在 YOLOv8-S 中，分类头（5.95G/1.51M）的浮点运算次数 (FLOPs) 和参数数量分别是回归头（2.34G/0.64M）的 2.5 倍和 2.4 倍。但是，在分析了分类误差和回归误差的影响（见表 6）后，我们发现回归头对 YOLO 的性能影响更大。因此，我们可以降低分类头的开销而不必担心会对性能产生很大影响。因此，我们为分类头采用了一个简单的轻量级架构，它由两个带 3x3 核大小的深度可分离卷积[24, 8] 和一个 1x1 卷积组成。



(2) 空间通道分离下采样。YOLOs 通常使用带有步幅为 2 的标准 3x3 卷积来实现空间下采样（从 HxW 变为 H/2xW/2）和通道变换（从 C 变为 2C）。这带来了相当大的计算成本，即 O(92HW C^2)，以及参数数量级为 O(18C^2)。相反，我们建议将空间减少和通道增加操作分开，从而实现更有效的下采样。具体来说，我们首先利用点卷积对通道维度进行调制，然后利用深度卷积进行空间下采样。这样可以将计算成本降低到 O(2HW C^2+92HW C)，并将参数数量降低到 O(2C^2+18C)。与此同时，它在下采样过程中最大化信息保留，从而在延迟降低的同时带来具有竞争力的表现。



(3) 排名引导块设计。YOLOs 通常为所有阶段使用相同的基砖[27,59]，例如 YOLOv8 [20] 中使用的瓶颈块。为了彻底检查适用于 YOLO 的这种同质化设计，我们利用内在排名[31, 15] 分析每个阶段的冗余性2。具体而言，我们在每个阶段的最后一层基本块中计算最后一个卷积的数值排名，该排名统计了大于给定阈值的奇异值的数量。图 3(a) 显示了 YOLOv8 的结果，表明深度阶段和大型模型更容易出现更多冗余。这一观察结果表明，仅对所有阶段应用相同的设计方案无法实现最佳容量效率权衡。为此，我们提出了一种基于排名的块设计方法，旨在通过紧凑的体系结构设计减少显示出来的阶段复杂度。我们首先介绍一个紧凑的倒置块（CIB）结构，它采用廉价的空间混合空洞卷积以及有效的通道混合全连接卷积低阶意味着更高的冗余，而高阶则表示更紧凑的信息。



如图 3 (b) 所示，混合。它可以作为高效的基砖，例如嵌入 ELAN 结构[58,20]（见图 3 (b)）。然后，我们提倡一种基于排名的块分配策略，以在保持竞争力的同时实现最佳效率。具体来说，给定一个模型，我们将它的所有阶段按其内在等级递增顺序排序。我们进一步检查用 CIB 替换前导阶段中的基本块时性能的变化。如果没有与给定模型相比性能下降，则继续替换下一个阶段，否则停止过程。因此，我们可以跨阶段和模型规模实施自适应紧凑型块设计，在不牺牲性能的情况下提高效率。由于页面限制，我们在附录中提供了算法的详细信息。



准确率驱动模型设计。我们进一步探索了大核卷积和自注意力，以提高准确率驱动的设计，并在最小成本下提高性能。



(1) 大核卷积。使用大核深度可分离卷积是一种有效的方法，可以扩大感受野并增强模型能力[9, 38, 37]。然而，在所有阶段都简单地使用它们可能会导致用于检测小物体的浅层特征受到污染，并且在高分辨率阶段引入显著的 I/O 负担和延迟[7]。因此，我们建议在 CIB 的深层阶段使用大核深度可分离卷积。具体来说，我们在 CIB 中将第二个 3×3 深度可分离卷积的内核大小增加到 7×7，以遵循[37]。此外，我们利用结构重参数化技术[10, 9, 53]引入另一个 3×3 深度可分离卷积分支来缓解优化问题而不会带来推理开销。此外，随着模型尺寸的增大，其感受野自然会扩大，从而减少了使用大核卷积的好处。因此，我们只在小模型规模时才采用大核卷积。



(2) 部分自注意（PSA）。由于其显著的全局建模能力，自注意力[52]被广泛应用于各种视觉任务[36, 13, 70]。然而，它具有很高的计算复杂度和内存占用。为此，我们在考虑常见的注意力头冗余[63]的基础上，提出了一个高效的PSA模块设计，如图3 (c) 所示。具体来说，在1×1卷积之后，我们均匀地将通道特征划分为两部分，并且仅将其中一部分馈入由多头自注意力模块（MHSA）和前馈网络（FFN）组成的NPSA块中。然后通过1×1卷积对这两部分进行拼接和融合。此外，我们遵循[21]将MHSA中的查询和键的维度设置为值的一半，并用批归一化（BatchNorm）[26]替代层归一化（LayerNorm），以实现快速推断。另外，为了避免自注意力的二次计算复杂度带来的过度开销，我们在分辨率最低的Stage 4之后放置了PSA。这样，我们可以将全局表征学习能力整合到YOLO模型中，从而在低计算成本下提高模型性能。



### 4 实验



### 4.1 实现细节



我们选择 YOLOv8 [20] 作为我们的基线模型，因为它在延迟准确度方面有很好的平衡，并且它可以在各种模型大小中使用。我们采用一致的双重分配来实现无 NMS 训练，并在此基础上进行整体效率准确率驱动的模型设计，从而带来了YOLOv10 模型。YOLOv10 和 YOLOv8 一样，也有 N / S / M / L / X 这样的变体。此外，我们还通过简单地增加 YOLOv10-M 的宽度比例因子推导出一个新的变体 YOLOv10-B。我们在相同从头开始训练设置[20, 59, 56]下验证了所提出的检测器。此外，所有模型的延迟都在遵循[71]的 T4 GPU 上以 TensorRT FP16 进行测试。



### 4.2 与最新技术的比较



如表 1 所示，我们的 YOLOv10 在各种模型规模上实现了最先进的性能和端到端延迟。我们首先比较了YOLOv10与我们的基线模型，即YOLOv8。在五个变体（N/S/M/L/X）中，YOLOv10 相比 YOLOv8 分别取得了 1.2%/1.4%/0.5%/0.3%/0.5% 的AP提升，参数减少了 28%/36%/41%/44%/57%，计算量减少了 23%/24%/25%/27%/38%，延迟降低了 70%/65%/50%/41%/37%。与其他 YOLO 模型相比，YOLOv10 还表现出对准确性和计算成本之间优越的权衡。具体来说，对于轻量级和小型模型，YOLOv10-N/S 比 YOLOv6-3.0-N/S 的 AP 高出 1.5 个单位，计算量少 2.0 倍。

![image](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1243709065485766656/1243709065485766656_cut_Table_1.png)



AP，分别具有 51％/ 61％ 和 41％/ 52％ 的更少参数和计算量。对于中等模型，在相同或更好的性能下，YOLOv10-B / M 比 YOLOv9-C / YOLO-MS 具有 46％/ 62％ 的更低延迟。对于大模型，与 Gold-YOLO-L 相比，我们的 YOLOv10-L 具有 68％ 更少的参数和 32％ 更低的延迟，并且在 AP 方面取得了显着的 1.4％ 提高。此外，与 RT-DETR 相比，YOLOv10 在性能和延迟方面取得了显着提高。值得注意的是，YOLOv10-S / X 在相似的表现下比 RT-DETR-R18 / R101 快了 1.8 倍和 1.3 倍。这些结果清楚地证明了 YOLOv10 作为实时端到端检测器的优势。

我们还使用原始的一对多训练方法比较了YOLOv10 和其他 YOLO。在这一场景下，我们考虑了模型前向过程（Latencyf）的性能和延迟，如 [56, 20, 54] 所述。表 1 显示出，在不同的模型规模中，YOLOv10 也显示出了最先进的性能和效率，这表明我们的架构设计的有效性。



### 4.3 模型分析



消融研究。我们在表2中展示了基于YOLOv10-S和YOLOv10-M的消融结果。可以观察到，我们的NMS免费训练与一致的双重分配显著减少了YOLOv10-S的端到端延迟4.63毫秒，同时保持了具有竞争力的性能AP为44.3%。此外，我们效率驱动的模型设计导致参数减少11.8M和计算量减少20.8GFlOPS，对于YOLOv10-M来说，延迟降低0.65毫秒，很好地显示了其有效性。此外，我们准确率驱动的模型设计在YOLOv10-S和YOLOv10-M上分别实现了1.8 AP和0.7 AP的显着改进，仅带来了0.18毫秒和0.17毫秒的延迟开销，这充分证明了它的优越性。

![image](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1243709065485766656/1243709065485766656_cut_Table_2.png)



表3：双分配。 表4：匹配度量标准。 表5：效率。 用于YOLOv10-S / M。



![image](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1243709065485766656/1243709065485766656_cut_Table_3.png)



### 无NMS训练分析

• 双标签分配。我们为无NMS的YOLO模型引入了双标签分配，可以同时在训练过程中提供一对一（o2o）分支的一对多（o2m）分支丰富的监督，并在推断时具有高效率。我们在 YOLOv8-S 上验证了它的优势，即表 2 中的 #1。具体来说，我们分别引入了仅使用 o2m 分支和仅使用 o2o 分支进行训练的基线。如表 3 所示，我们的双标签分配实现了最佳 AP 渐进速度比。



一致匹配度量。 我们引入了一致匹配度量，以使一对一头部与一对多头部更加协调。我们在不同的 αo2o 和 βo2o 下验证了其优势，如表 2 中所示，YOLOv8-S（即表格中的 #1）在不同的 αo2o 和 βo2o 下进行了验证。 表 4 显示，我们提出的一致匹配度量，即 αo2o = r * αo2m 和 βo2o = r * βo2m，在一对一头部中可以实现最佳性能，其中一对一头部中 αo2m = 0.5 和 βo2m = 6.0 [20]。这种改进可归因于监督差距的减少（方程式 (2)），这为两个分支之间提供了更好的监督对齐。此外，我们提出的一致匹配度量消除了对超参数进行穷举调整的需求，这对于实际场景非常有吸引力。



效率驱动模型设计分析。我们进行实验，逐步在基于YOLOv10-S/M 的效率驱动设计元素中融入效率驱动的设计。我们的基线是不包含效率-准确性驱动模型设计的YOLOv10-S/M 模型，即表2中的#2/#6。如表5所示，每个设计组件（包括轻量级分类头、空间通道分离下采样和排名引导块设计）都有助于减少参数数量、浮点运算次数和延迟。重要的是，这些改进是在保持竞争性能的同时实现的。



• 轻量级分类头。我们根据表5中YOLOv10-S的 #1 和 #2 来分析预测类别和定位误差对性能的影响，就像[6]一样。具体来说，我们通过一对一的分配将预测与实例匹配。然后，我们将预测的类别分数替换为实例标签，从而得到没有分类错误的 APvalw/o c。类似地，我们将预测的位置替换为实例的位置，从而得到没有回归错误的 APval w/o r。如表6所示，APval w/o r 比 APval w/o c 高很多，这表明消除回归错误可以实现更大的改进。因此，性能瓶颈更多地在于回归任务。因此，采用轻量级分类头可以在不降低性能的情况下提高效率。



• 空间通道解耦下采样。为了提高效率，我们对下采样操作进行了分离，首先通过点卷积（PW）增加通道维度，然后通过深度卷积（DW）降低分辨率以实现最大信息保留。我们在表5中基于YOLOv10-S#3比较了它与基线方法的空间降维，即先进行DW降维，再进行PW通道调制。如表7所示，我们的下采样策略在下采样过程中享受更少的信息损失，实现了0.7% 的AP提升。



• 紧凑倒金字塔块。我们引入紧凑的基本构建块。我们在表5中基于YOLOv10-S的#4验证了它的有效性。具体来说，我们将倒残余块[46]作为基线，如表8所示，它实现了次优的43.7% AP。然后我们在其后附加一个3x3深度卷积（DW），标记为“IRB-DW”，它



![image](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1243709065485766656/1243709065485766656_cut_Table_6.png)



![image](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1243709065485766656/1243709065485766656_cut_Table_10.png)



带来了0.5％的AP改进。与“ IRB-DW”相比，我们的CIB通过在具有最小开销的情况下添加另一个DW进一步实现了0.3％的AP改进，这表明其优越性。



• 排名引导块设计。我们引入了排名引导块设计，以自适应地整合紧凑块设计，从而提高模型效率。我们在表5中的YOLOv10-S #3中验证了其益处。根据内在等级排序的阶段按顺序排列，如图3所示。(a) 。表9显示，在每个阶段逐渐用高效的CIB替换瓶颈块时，从第7个阶段开始性能下降。因此，在具有较低内在等级和更多冗余的第8和第4阶段中，我们可以采用高效的设计而不影响性能。这些结果表明，排名引导块设计可以作为提高模型效率的有效策略。



准确率驱动模型设计分析。我们根据YOLOv10-S/M逐步整合了准确率驱动的设计元素，并以表格2中基于效率驱动设计的YOLOv10-S/M模型作为基准。如表10所示，在采用大卷积核和PSA模块的情况下，YOLOv10-S在增加最小延迟0.03毫秒和0.15毫秒的情况下分别实现了0.4%和1.4%的AP显着提升。请注意，YOLOv10-M并未使用大卷积核（参见表12）。



大核卷积。我们在表10中基于YOLOv10-S的#2研究了不同内核大小的影响。如表11所示，随着内核大小的增加性能提高，在7×7左右达到瓶颈，这表明大感知场的好处。此外，在训练过程中移除重参数化分支会导致0.1%AP的下降，说明其对优化的有效性。此外，我们还检查了在不同的模型规模上使用大核卷积所带来的好处，基于YOLOv10-N/S/M。如表12所示，由于其固有的广阔的感受野，对于大型模型（例如YOLOv10-M），它并没有带来任何改进。因此，我们只针对小型模型（即YOLOv10-N/S）采用大核卷积。



部分自注意力（PSA）。我们引入了PSA来以最小成本增强性能，通过利用全局建模能力。我们在表10中基于YOLOv10-S #3 验证其有效性。具体来说，我们将Transformer块，即多头自注意力(MHSA)后接前馈网络(FFN)，作为基线，“Trans”。如表13所示，与之相比，PSA带来了0.3%AP的提升以及0.05毫秒的延迟降低。性能提升可能是由于缓解了自注意力中的优化问题[62,9]，减轻了头部之间的冗余。此外，我们研究了不同NPSA的影响。如表13所示，将NPSA增加到2可以带来0.2%AP的提高，但会有0.1毫秒的延迟开销。因此，为了在保持高效率的同时增强模型能力，我们默认设置NPSA为1。



### 5 结论

在本文中，我们针对YOLO检测管道中的后处理和模型架构进行优化。对于后处理，我们提出了无NMS训练的一致性双重分配，实现了高效的端到端检测。对于模型架构，我们引入了以整体效率和准确性为导向的设计策略，提高了性能与效率之间的权衡。这些方法带来了新的实时端到端目标检测器YOLOv10。广泛的实验表明，YOLOv10 在与其他先进检测模型相比时，在最先进的性能和延迟方面取得了显著优势，很好地证明了其优越性。